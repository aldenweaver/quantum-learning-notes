# Navigating Generative AI [IBM Technical Talk] Notes
[IBM Meetup on Generative AI 2024-01-018](https://ibm.webex.com/webappng/sites/ibm/meeting/info/bcc266265ac34a0eb5d2b33c691836f9?MTID=m799de1ffbcfb5509292b88e98c2395f8&siteurl=ibm&meetingAuthToken=QUhTSwAAAAaLG7miZC6Z4tnORXEqpD6aFlu37v8x0druaZ5lQrlkBQrcR23XGe8yxLFu23V7FzM8jThdu4AiFcsS3CwbLDc8cZbYOls3B7i5ryagnddPclwWy8UjFCCffeorEm2mJGHg9ac2H%2FKIzQ43CcxHbPUfbCxyG2brbbLh9jrAJATQ39zZVGjiHifCQQnN8f0Tm4gEt7iGpp8VkWzseOih5lCOPrlrql40PMhjDyxhrEgQPQ%3D%3D)

## Quantum Series every two weeks
+ Quantum Series 1: Jan 31 & Feb 1
+ Quantum Series 2: Feb 14 & Feb 15
+ Quantum Series 3: Feb 28 & Feb 29
+ Quantum Series 4: March 13 & March 14

## Navigating AI for Content Creation Notes
+ Balance in AI utlization & use cases
+ Artificial intelligence: "The emulation of natural intelligence by a machine"

## Analytical AI vs. Generative AI
  + Analytical AI 
    + Classifying
    + Predicting
    + Analyzing sentiment
  + Generative AI
    + Text generation
    + Image generation
    + Creating new artifacts

+ (My Notes TODO): Generative AI for generating new formulae for quantum

## Machine Learning & Models
+ Machine Learning is a type of AI that learns from patterns & examples
  + Classification models: train models to find patterns based on data sets
  + Predictions based on trained model(s)
  + Purpose-built models
  + Foundation models are what powers Generative AI
  + My note TODO: Train foundation models for specific purposes
  + Large language models & diffusion models based on foundation models
  + OpenAI trained GPT-3 on a large set of data (45 TB - `space`) called the "Common Crawl" - most of the internet at a specific point in `time`
  + (My Notes TODO): Space measured in time? (i.e., 1 TB holds 1000 hrs/40 days of video)
    + 1 TB = 40 days ???
  + PromptLab is an IBM tool using watsonx
  + AI can be trained based on reality or social constructs/langugae/colloquialism/rhyme patterns
    + i.e., "Roses are red, violets are_"
      + Blue? Violet?
    + i.e., "Sugar is sweet, & my dog ate _."
  + Diffusion & reverse diffusion to produce a different image via noise (my note TODO ???)
  + Images diffused based on pixels/small measurements/items?, then rearranged via noise (or sound? static?) to recreate a different/new image

## Stories
+ Story telling, story writing, story beats 
+ Different character, mentor, plot creation
+ Story arcs & predictions
+ Story lessons & morales
+ Tying into different language meanings, layers of meaning, coloquialisms, texts, translations, theologies

## Images
+ Fine-tuned models
+ Input of data affects results
  + What data is being inputed, how, & how it is interpreted then used affects the result
  
## Data Sets, Predictive Models, & Generative Models (My Notes TODO): 
  + Differenct depictions & descriptions based on fine tuning models using different data sets
  + Ripple effects of errors
    + Errors due to improper data input, improper data analysis, &/or improper model tuning/training
    + Fine tuning algorithms & the ripple effects
  + Data structures
    + Also leveraging behavior/tendencies/magnetisms of data structures to predict ripple effects? 
    + Data structures in nature aka Natural Data Structures
  
## Connecting AI & Quantum (My Notes TODO)
+ Data sets, data models
+ Patterns & predictions
  + Assists in positive performance
  + Assists in error mitigation
+ Different depictions & descriptions based on fine tuning models using different data sets
+ Generative AI for missing quantum formulae & theoretical options
  
## Prompting
+ Generative Variability: Every time the AI generates a response, it will not be exactly the same as before. It varies every time.


## Prompting (My Notes TODO)
+ Generative variability in Generative AI is a result of the AI always learning, changing, & leveraging different resources
  + This is the same with people, nature, etc
Observing & training something affects its behavior (Schrodinger, quantum observability)
+ Get your prompt right to get the right response!
  + Refine input & function to get the correct response
  + This can be a complicated process to achieve the proper result
  + Complicated processes require more resources
  + How to minimize resources for maximal results? 
    + Spend the least, get the most
  
## Prompt Engineering
+ Can use IBM Prompt Lab to experiment training AI via different prompts
+ Prompt engineering: The process of designing natural language prompts for a language model to perform specific task
+ Prompt precision
  + Precise prompts lead to getting closer to the optimal results
  
## Prompt Engineering (My Notes TODO)
  + How to measure precision of prompts?
  + Sound is an intersection of language & pitch (& ? time/timing?)
    + Applying this to quantum error noise & quantum error mitigation

## Privacy & AI Data Sets
  + AI education for artists
  + haveibeentrained.com
    + Detects if your images have been used to train AI? Allows you to opt out
  + European AI Act: seeking to promote human-safe AI with integrity
  + Where does AI training data come from & disclosures/policies around it
  + White House AI Bill of Rights
  + Neilsen Norman group studies 
    + Study on "Time Spent on Writing Subtasks"
  + Levels of trust of AI inputs & results
  + "As AI tools improve, authors have to double down on being human" - AI for Authors: [Practical & Ethical Guidelines by the Alliance of Independent Authors](https://selfpublishingadvice.org/ai-for-authors-guidelines/)
  + Building applications on top of a certain model subjects you to the training (good or bad) of that model


## Privacy & AI Data Sets (My Notes TODO)
  + How to quantify trust? Especially in relation to AI
  + Levels of trust of inputs
  + Levels of trust of outputs
  + Building applications on top of a certain model subjects you to the training (good or bad) of that model
      +  "Real life hard to come by, too many systems change us." - Alexandra Weaver
